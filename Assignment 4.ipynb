{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 4: Pipelines and Hyperparameter Tuning (32 total marks)\n",
    "### Due: November 22 at 11:59pm\n",
    "\n",
    "### Name: Brandon Lac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will be putting together everything you have learned so far. You will need to find your own dataset, do all the appropriate preprocessing, test different supervised learning models and evaluate the results. More details for each step can be found below.\n",
    "\n",
    "### You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "## Step 1: Data Input (4 marks)\n",
    "\n",
    "Import the dataset you will be using. You can download the dataset onto your computer and read it in using pandas, or download it directly from the website. Answer the questions below about the dataset you selected. \n",
    "\n",
    "To find a dataset, you can use the resources listed in the notes. The dataset can be numerical, categorical, text-based or mixed. If you want help finding a particular dataset related to your interests, please email the instructor.\n",
    "\n",
    "**You cannot use a dataset that was used for a previous assignment or in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_genuine</th>\n",
       "      <th>diagonal</th>\n",
       "      <th>height_left</th>\n",
       "      <th>height_right</th>\n",
       "      <th>margin_low</th>\n",
       "      <th>margin_up</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>171.81</td>\n",
       "      <td>104.86</td>\n",
       "      <td>104.95</td>\n",
       "      <td>4.52</td>\n",
       "      <td>2.89</td>\n",
       "      <td>112.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>171.46</td>\n",
       "      <td>103.36</td>\n",
       "      <td>103.66</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2.99</td>\n",
       "      <td>113.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>172.69</td>\n",
       "      <td>104.48</td>\n",
       "      <td>103.50</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.94</td>\n",
       "      <td>113.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>171.36</td>\n",
       "      <td>103.91</td>\n",
       "      <td>103.94</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.01</td>\n",
       "      <td>113.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>171.73</td>\n",
       "      <td>104.28</td>\n",
       "      <td>103.46</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.48</td>\n",
       "      <td>112.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>False</td>\n",
       "      <td>171.75</td>\n",
       "      <td>104.38</td>\n",
       "      <td>104.17</td>\n",
       "      <td>4.42</td>\n",
       "      <td>3.09</td>\n",
       "      <td>111.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>False</td>\n",
       "      <td>172.19</td>\n",
       "      <td>104.63</td>\n",
       "      <td>104.44</td>\n",
       "      <td>5.27</td>\n",
       "      <td>3.37</td>\n",
       "      <td>110.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>False</td>\n",
       "      <td>171.80</td>\n",
       "      <td>104.01</td>\n",
       "      <td>104.12</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.36</td>\n",
       "      <td>111.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>False</td>\n",
       "      <td>172.06</td>\n",
       "      <td>104.28</td>\n",
       "      <td>104.06</td>\n",
       "      <td>5.17</td>\n",
       "      <td>3.46</td>\n",
       "      <td>112.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>False</td>\n",
       "      <td>171.47</td>\n",
       "      <td>104.15</td>\n",
       "      <td>103.82</td>\n",
       "      <td>4.63</td>\n",
       "      <td>3.37</td>\n",
       "      <td>112.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_genuine  diagonal  height_left  height_right  margin_low  margin_up  \\\n",
       "0           True    171.81       104.86        104.95        4.52       2.89   \n",
       "1           True    171.46       103.36        103.66        3.77       2.99   \n",
       "2           True    172.69       104.48        103.50        4.40       2.94   \n",
       "3           True    171.36       103.91        103.94        3.62       3.01   \n",
       "4           True    171.73       104.28        103.46        4.04       3.48   \n",
       "...          ...       ...          ...           ...         ...        ...   \n",
       "1495       False    171.75       104.38        104.17        4.42       3.09   \n",
       "1496       False    172.19       104.63        104.44        5.27       3.37   \n",
       "1497       False    171.80       104.01        104.12        5.51       3.36   \n",
       "1498       False    172.06       104.28        104.06        5.17       3.46   \n",
       "1499       False    171.47       104.15        103.82        4.63       3.37   \n",
       "\n",
       "      length  \n",
       "0     112.83  \n",
       "1     113.09  \n",
       "2     113.16  \n",
       "3     113.51  \n",
       "4     112.54  \n",
       "...      ...  \n",
       "1495  111.28  \n",
       "1496  110.97  \n",
       "1497  111.95  \n",
       "1498  112.25  \n",
       "1499  112.07  \n",
       "\n",
       "[1500 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset (1 mark)\n",
    "df = pd.read_csv(\"./fake_bills.csv\", delimiter = \";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20316765",
   "metadata": {},
   "source": [
    "### Questions (3 marks)\n",
    "\n",
    "1. (1 mark) What is the source of your dataset?\n",
    "\n",
    "The source of the dataset is from Kaggle.\n",
    "\n",
    "1. (1 mark) Why did you pick this particular dataset?\n",
    "\n",
    "I picked this dataset because I think it would be quite interesting to see how ML would be able to predict fraudlant bills from this dataset.\n",
    "1. (1 mark) Was there anything challenging about finding a dataset that you wanted to use?\n",
    "\n",
    "The challenging aspect was finding a dataset that wasnt too large as it would then take longer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "## Step 2: Data Processing (5 marks)\n",
    "\n",
    "The next step is to process your data. Implement the following steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afc244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_genuine       0\n",
      "diagonal         0\n",
      "height_left      0\n",
      "height_right     0\n",
      "margin_low      37\n",
      "margin_up        0\n",
      "length           0\n",
      "dtype: int64\n",
      "is_genuine      0\n",
      "diagonal        0\n",
      "height_left     0\n",
      "height_right    0\n",
      "margin_low      0\n",
      "margin_up       0\n",
      "length          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean data (if needed)\n",
    "df.dtypes\n",
    "print(df.isna().sum())\n",
    "df.dropna(inplace = True)\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70a8c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement preprocessing steps. Remember to use ColumnTransformer if more than one preprocessing method is needed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_features = df.drop(columns=[\"is_genuine\"])\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data_features, df.is_genuine, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c46b7",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "\n",
    "1. (1 mark) Were there any missing/null values in your dataset? If yes, how did you replace them and why? If no, describe how you would've replaced them and why.\n",
    "\n",
    "2. (1 mark) What type of data do you have? What preprocessing methods would you have to apply based on your data types?\n",
    "\n",
    "\n",
    "There were missing values in this dataset for margin_low, since there was only 32 of the rows that were missing this value, dropping the rows was the best choice.\n",
    "\n",
    "The data that I have is numerical and I would only have to apply standard scaler to the data as there are no extreme outliers, the standard scaler was a good choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "## Step 3: Implement Machine Learning Model (11 marks)\n",
    "\n",
    "In this section, you will implement three different supervised learning models (one linear and two non-linear) of your choice. You will use a pipeline to help you decide which model and hyperparameters work best. It is up to you to select what models to use and what hyperparameters to test. You can use the class examples for guidance. You must print out the best model parameters and results after the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5558a776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'clf__C': 0.1}\n",
      "\n",
      "Best cross-validation train score: 0.99\n",
      "Best cross-validation validation score: 0.99\n",
      "Best params:\n",
      "{'clf__max_depth': 5, 'clf__n_estimators': 100}\n",
      "\n",
      "Best cross-validation train score: 1.00\n",
      "Best cross-validation validation score: 0.99\n",
      "Best params:\n",
      "{'clf__C': 10, 'clf__gamma': 0.01}\n",
      "\n",
      "Best cross-validation train score: 0.99\n",
      "Best cross-validation validation score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Implement pipeline and grid search here. Can add more code blocks if necessary\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "pipeline_lr = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000))])\n",
    "pipeline_rf = Pipeline([('clf', RandomForestClassifier(random_state=42))])\n",
    "pipeline_svm = Pipeline([('scaler', StandardScaler()), ('clf', SVC())])\n",
    "\n",
    "#Implementing grid parameters \n",
    "param_grid_lr = {'clf__C': [0.1, 1, 10]}\n",
    "param_grid_rf = {'clf__max_depth': [5, 10, 15], 'clf__n_estimators': [100, 200, 300]}\n",
    "param_grid_svm = {'clf__C': [0.1, 1, 10], 'clf__gamma': [0.001, 0.01]}\n",
    "\n",
    "grid_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=5, return_train_score=True)\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, return_train_score=True)\n",
    "grid_svm = GridSearchCV(pipeline_svm, param_grid_svm, cv=5, return_train_score=True)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\\n{}\\n\".format(grid_lr.best_params_))\n",
    "print(\"Best cross-validation train score: {:.2f}\".format(grid_lr.cv_results_['mean_train_score'][grid_lr.best_index_]))\n",
    "print(\"Best cross-validation validation score: {:.2f}\".format(grid_lr.best_score_))\n",
    "\n",
    "print(\"Best params:\\n{}\\n\".format(grid_rf.best_params_))\n",
    "print(\"Best cross-validation train score: {:.2f}\".format(grid_rf.cv_results_['mean_train_score'][grid_rf.best_index_]))\n",
    "print(\"Best cross-validation validation score: {:.2f}\".format(grid_rf.best_score_))\n",
    "\n",
    "print(\"Best params:\\n{}\\n\".format(grid_svm.best_params_))\n",
    "print(\"Best cross-validation train score: {:.2f}\".format(grid_svm.cv_results_['mean_train_score'][grid_svm.best_index_]))\n",
    "print(\"Best cross-validation validation score: {:.2f}\".format(grid_svm.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd7075",
   "metadata": {},
   "source": [
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Do you need regression or classification models for your dataset?\n",
    "1. (2 marks) Which models did you select for testing and why?\n",
    "1. (2 marks) Which model worked the best? Does this make sense based on the theory discussed in the course and the context of your dataset?\n",
    "\n",
    "Classification is needed for this model as its a binary of true and false, not predicting continous values\n",
    "\n",
    "Required 2 non-linear models, SVM and random forest was picked due to ease of setting up and better knowledge of both. Logical regression was the linear model that was picked because it was the most simple.\n",
    "\n",
    "It looks like all of the models have done a very good job of doing a good job in training score and validation score. I would pick the random forest because it has the highest training score. All the models have done a good job in predicting the outcome, which means that the data is very indicative of classication. Random forest make more sense in being better as it picks the features that are more useful thus creating a better model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "## Step 4: Validate Model (6 marks)\n",
    "\n",
    "Use the testing set to calculate the testing accuracy for the best model determined in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69e64c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy of Random Forest Model: 0.9918032786885246\n"
     ]
    }
   ],
   "source": [
    "# Calculate testing accuracy (1 mark)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_model = grid_rf.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "pred = best_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, pred)\n",
    "print(f\"Validation Accuracy of Model: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4529ba",
   "metadata": {},
   "source": [
    "\n",
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Which accuracy metric did you choose? \n",
    "1. (1 mark) How do these results compare to those in part 3? Did this model generalize well?\n",
    "1. (3 marks) Based on your results and the context of your dataset, did the best model perform \"well enough\" to be used out in the real-world? Why or why not? Do you have any suggestions for how you could improve this analysis?\n",
    "\n",
    "Used the default accuracy metric of r^2.\n",
    "\n",
    "The results from part 3 were almost identical, it means that the model was able to generalize well and predict the outcome perfectly.\n",
    "\n",
    "The model performed perfectly, there is nothing that would need to be changed for it to perform well in the real world. Initally when the high testing and vaildation scores was resulted in the previous section, i had my suspicions that it would be over fitting but with the accuracy score, it has solidified that the model is perfect. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "## Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "Bulk of the code was taking from the class example of \"Imputation Example\".\n",
    "\n",
    "Followed the steps from top to bottom. \n",
    "\n",
    "No generative AI was used in order to complete the assignment. The steps were pretty straight forward.\n",
    "\n",
    "The challenging parts of the assignment was applying the grid search as we have not applied them in our previous labs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "I throughly enjoyed using the pipline to apply the scaling instead of spilting the task up into various lines.\n",
    "\n",
    "The motitvating aspect of this lab was that applying 3 different models was quite easy and not time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
